{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job1: All-Source Intelligence Analyst\n",
    "\n",
    "Pragmatics\n",
    "\n",
    "[link](https://www.indeed.com/q-Intelligence-Analyst-jobs.html?advn=4049699754031189&vjk=2ed3890be0595ad9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job2: Intelligence Analyst SME 1\n",
    "\n",
    "Perspecta\n",
    "\n",
    "[link](https://www.indeed.com/q-Intelligence-Analyst-jobs.html?advn=984457265069156&vjk=e36195b0e661c129)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt        \n",
    "\n",
    "from collections import Counter        \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "  \n",
    "\n",
    "book = xlwt.Workbook() # create a new excel file\n",
    "\n",
    "sheet_test = book.add_sheet('word_count') # add a new sheet\n",
    "\n",
    "i = 0\n",
    "\n",
    "sheet_test.write(i,0,'word') # write the header of the first column\n",
    "\n",
    "sheet_test.write(i,1,'count') # write the header of the second column\n",
    "\n",
    "sheet_test.write(i,2,'ratio') # write the header of the third column\n",
    "\n",
    "    \n",
    "\n",
    "with open('job1.txt','r',encoding='utf-8', errors = 'ignore') as text_word: # define the location of your txt file\n",
    "\n",
    "     \n",
    "\n",
    "    # convert all the word into lower cases\n",
    "\n",
    "    # filter out stop words\n",
    "\n",
    "    word_list = [i for i in text_word.read().lower().split() if i not in stop]\n",
    "\n",
    "    word_total = word_list.__len__()\n",
    "\n",
    "     \n",
    "\n",
    "    count_result =  Counter(word_list)\n",
    "\n",
    "    for result in count_result.most_common(10):\n",
    "\n",
    "        i = i+1 \n",
    "\n",
    "        sheet_test.write(i,0,result[0])\n",
    "\n",
    "        sheet_test.write(i,1,result[1])\n",
    "\n",
    "        sheet_test.write(i,2,(result[1]/word_total))\n",
    "\n",
    "    \n",
    "\n",
    "book.save('job1.xls')# define the location of your excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt        \n",
    "\n",
    "from collections import Counter        \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "  \n",
    "\n",
    "book = xlwt.Workbook() # create a new excel file\n",
    "\n",
    "sheet_test = book.add_sheet('word_count') # add a new sheet\n",
    "\n",
    "i = 0\n",
    "\n",
    "sheet_test.write(i,0,'word') # write the header of the first column\n",
    "\n",
    "sheet_test.write(i,1,'count') # write the header of the second column\n",
    "\n",
    "sheet_test.write(i,2,'ratio') # write the header of the third column\n",
    "\n",
    "    \n",
    "\n",
    "with open('job2.txt','r',encoding='utf-8', errors = 'ignore') as text_word: # define the location of your txt file\n",
    "\n",
    "     \n",
    "\n",
    "    # convert all the word into lower cases\n",
    "\n",
    "    # filter out stop words\n",
    "\n",
    "    word_list = [i for i in text_word.read().lower().split() if i not in stop]\n",
    "\n",
    "    word_total = word_list.__len__()\n",
    "\n",
    "     \n",
    "\n",
    "    count_result =  Counter(word_list)\n",
    "\n",
    "    for result in count_result.most_common(10):\n",
    "\n",
    "        i = i+1 \n",
    "\n",
    "        sheet_test.write(i,0,result[0])\n",
    "\n",
    "        sheet_test.write(i,1,result[1])\n",
    "\n",
    "        sheet_test.write(i,2,(result[1]/word_total))\n",
    "\n",
    "    \n",
    "\n",
    "book.save('job2.xls')# define the location of your excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"sheet1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"sheet2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'These', 'maritime', 'qualified', 'operation,', 'analysis.', 'Systems', 'Products-MS', 'regards', 'reports', 'civilian', 'several', 'working', 'shipping,', 'sterling', 'service.', 'HUMINT', 'its', 'Since', 'will', 'Insurance', 'clients', 'facility.', 'task', '(including', 'Proficiency', 'technology', 'Departments', 'Database', 'mid-', 'Treasury;', 'branch', 'Agency;', 'religion,', 'capable', 'reputation', 'Pragmatics,', 'their', 'Support', 'has', 'agencies.', 'basis', 'intelligence', 'maintained', 'cases,', 'Maritime', '(HOT-R)', 'performing', 'Microsoft', 'national', 'three', 'status,', 'Opportunity', 'Federal', 'if', 'disability,', 'open', 'classification', 'processing', 'contracts', 'Analyst,', 'brief', 'race,', 'without', 'reservists', 'For', 'Equal', 'trusted,', 'Naval', 'all', 'customer', 'Employer.', 'Administration;', 'provided', 'highest', 'achieving', 'DRs.', 'train', 'than', 'Agencies.', 'focus', 'high-impact', 'General', 'Employment', 'information', 'Tasking', '25', 'employment', 'senior-level', 'age,', 'ship', 'operational', 'personnel', 'laws.', 'Program.', 'As', 'Online', 'military', 'service', 'pregnancy),', 'Office', 'civil', 'Security,', 'Health', 'same', 'seeking', 'research', 'Management', 'assessments.', 'Merchant', 'Inc.', 'Army,', 'Services', 'Word', 'from', 'accommodations,', 'solutions', 'marital', 'Reporting', 'Navy', 'decades,', 'Defense', 'so', 'success', '#Dice', 'award-winning', 'qualifications:', 'currently', 'HOT', 'Proficient', 'overview:', 'prohibits', 'any', 'Justice,', 'Services,', 'source', 'continuing', 'deliver', 'applicants', 'experts', 'reasonable', 'disabilities,', 'Civilian', 'industry-leading', 'User', 'Power', 'it', 'proud', 'major', 'characteristics', '-R', 'provider.', 'origin,', 'Homeland', 'hardship.', 'IC.', 'following', 'Industry', 'sex', 'do', 'perform', 'Information', 'Pragmatics', 'level', 'A', 'veteran', 'building,', 'officials.', 'against', 'color,', 'Deposit', 'responsibilities:', 'State,', 'discrimination', '1985,', '2', 'them', 'Point.', 'Company', 'author', 'preferred.', 'provide', 'forward', 'individuals', 'Human', 'skills.', 'expert', 'Data', 'more', 'Corporation;', 'undue', 'research.', 'Team', 'portfolio', 'include', 'Source', 'appropriate'}\n",
      "{'May', 'packages,', 'plan,', 'and/or', 'single', 'clearly', 'functions,', 'design', 'Advanced', 'study', 'works', 'effectively,', 'functions', 'set', 'nature;', 'processes,', 'where', 'developers,', 'matter.', 'responsibilities', 'concepts', 'manage', 'accept', 'solving', 'policies,', 'techniques', 'Matter', 'quantitative', 'serve', 'defense,', 'salaries', 'possess:', '1', '-', 'assessment', 'U.S.', 'state', 'markets.', 'Mastery', 'create', 'relative', 'reports,', 'logical,', 'includes', 'programs', 'methods', 'engineers,', 'high-caliber', 'only', 'methodology,', 'jobs', 'following:', 'seven', 'tasks', 'concise', 'customers.', 'theories,', 'department', 'preparing', 'Every', 'effect', 'may', 'day', 'effectively', 'analytical', 'together', 'talented', 'strongstands', 'welcome', 'program', 'not', 'workforce14,000', 'but', 'tables,', 'approaches,', 'robust', 'identify', 'principles,', 'customers', 'analysts,', 'never', 'continually', 'further.', 'are', 'meaningful', 'competitive', 'Employer', 'orders,', 'within', 'Perform', 'duties', 'tactfully', 'graphs', 'tirelessly', 'implement', 'Perspectas', 'qualitative', 'key', 'projects,', 'briefings,', 'work.', 'many', 'distributed.', 'architects', 'procedures', 'research,', 'guide', 'changing', 'team', 'conclusions', 'variety', 'presentations', 'bound', 'informal', 'both', 'civilian,', 'people', 'Lets', 'making', 'Expert', 'studies', 'directives,', 'broad', 'formal', 'Minorities/Women/Veterans/Disabled', 'waysnot', 'coverage', 'Our', '(7)', 'through', 'ready', 'local', 'categories', 'well-documented', 'around', 'The', 'Ideal', 'improvement', 'limited', 'capabilities', 'founded', 'go', 'benefits', 'systems,', 'precedents', 'Qualifications:', 'programs,', 'effectiveness', 'knowledge', 'direct', 'mission', 'respond,', 'Shall', 'thousands', 'To', 'nations', 'comprehensive', 'issues', 'partner', 'landscape', 'ourselvesto', 'impact', 'survey', 'also', 'clear,', 'stop', 'laws,', 'agencies', 'practices,', 'Candidate', 'charts,', 'develop', 'complete,', 'new', 'take', 'structure,', 'negotiate', 'difficult', 'recommendations', 'at', 'correspondence,', 'listed', 'required', 'regulations,', 'hundreds', 'findings', 'integrators', 'determine', 'oversee', 'Minimum', 'persuasively', 'intelligence,', 'company', 'wide', 'order', 'Degree', 'application', 'promise:', 'writing,', 'skills,', 'Subject', 'together.', 'enable', 'projects', 'adapt,', 'ahead', 'investigators,', 'opportunity', 'mastery', 'advise', 'extremely', 'team.', 'Perspecta,', 'orally', 'include,', 'solutions.', 'care,', 'delicate', 'relationships', 'most', 'health', 'boundaries', 'Provide', 'overall', 'Were', 'Perspecta', 'Comprehensive', 'clock', 'Quickly', 'communicate', 'push', 'management', 'that', 'AA/EEO', 'organize,', 'diverse', 'ways', 'We', 'administrative', 'rewarded', 'relevant', 'assigned', 'above'}\n"
     ]
    }
   ],
   "source": [
    "with open('job1.txt','r',encoding='utf-8', errors = 'ignore') as job1:\n",
    "    with open('job2.txt','r',encoding='utf-8', errors = 'ignore') as job2:\n",
    "        job1_str = job1.read()\n",
    "        job2_str = job2.read()\n",
    "        \n",
    "        job1_set = set(job1_str.split())\n",
    "        job2_set = set(job2_str.split())\n",
    "        \n",
    "        print(job1_set.difference(job2_set))\n",
    "        print(job2_set.difference(job1_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "with open('job1.txt','r',encoding='utf-8', errors = 'ignore') as job1:\n",
    "    with open('job2.txt','r',encoding='utf-8', errors = 'ignore') as job2:\n",
    "        job1_str = job1.read()\n",
    "        job2_str = job2.read()\n",
    "\n",
    "        print(fuzz.token_sort_ratio(job1_str,job2_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
